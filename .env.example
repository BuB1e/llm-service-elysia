# LLM Service Environment Variables

# LLM Provider (groq, ollama, lmstudio, openai)
LLM_PROVIDER=groq

# Groq (required if LLM_PROVIDER=groq)
GROQ_API_KEY=your-groq-api-key
GROQ_MODEL=llama-3.1-8b-instant

# Ollama/LMStudio (required if LLM_PROVIDER=ollama or lmstudio)
OLLAMA_URL=http://localhost:11434
OLLAMA_MODEL=llama3

# OpenAI (required if LLM_PROVIDER=openai)
OPENAI_API_KEY=your-openai-api-key
OPENAI_MODEL=gpt-4.1-mini

# Security (required for production)
API_KEYS=your-secret-api-key-1,your-secret-api-key-2

# Rate Limiting
RATE_LIMIT_RPM=30

# Server
PORT=3000
